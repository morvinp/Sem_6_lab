{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/Desktop/220962029/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Cats and Dogs dataset...\n",
      "Dataset extracted to cats_and_dogs_filtered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = 'cats_and_dogs_filtered'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Downloading Cats and Dogs dataset...\")\n",
    "    dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
    "    dataset_path = \"cats_and_dogs_filtered.zip\"\n",
    "    \n",
    "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
    "\n",
    "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    print(f\"Dataset extracted to {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7503085675693694\n",
      "Epoch [2/10], Loss: 0.693732309909094\n",
      "Epoch [3/10], Loss: 0.6932253960579161\n",
      "Epoch [4/10], Loss: 0.6932200600230505\n",
      "Epoch [5/10], Loss: 0.693252356279464\n",
      "Epoch [6/10], Loss: 0.6932271671673608\n",
      "Epoch [7/10], Loss: 0.6932206664766584\n",
      "Epoch [8/10], Loss: 0.6932709737429543\n",
      "Epoch [9/10], Loss: 0.6932072885452755\n",
      "Epoch [10/10], Loss: 0.6931886985188439\n",
      "With L2 norm:\n",
      "Epoch [1/10], Loss: 0.7519503699408637\n",
      "Epoch [2/10], Loss: 0.7403952346907722\n",
      "Epoch [3/10], Loss: 0.7336394654379951\n",
      "Epoch [4/10], Loss: 0.7258287583078656\n",
      "Epoch [5/10], Loss: 0.72342782739609\n",
      "Epoch [6/10], Loss: 0.7186134883335659\n",
      "Epoch [7/10], Loss: 0.710716169977945\n",
      "Epoch [8/10], Loss: 0.7068073531937977\n",
      "Epoch [9/10], Loss: 0.7039466774652875\n",
      "Epoch [10/10], Loss: 0.7020383997569009\n"
     ]
    }
   ],
   "source": [
    "#question 1\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  # Adjusted for 256x256 image size\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),         \n",
    "])\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01) \n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(inputs)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print(\"With L2 norm:\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    l2_lambda = 0.01  \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        l2_reg = 0\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param, 2)  \n",
    "        \n",
    "        loss += l2_lambda * l2_reg  \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with L1 regularization (Optimizer)\n",
      "Epoch [1/10], Loss: 165.08566538492838\n",
      "Epoch [2/10], Loss: 90.13900466192337\n",
      "Epoch [3/10], Loss: 89.55810583205451\n",
      "Epoch [4/10], Loss: 89.67102232433501\n",
      "Epoch [5/10], Loss: 89.50572228810144\n",
      "Epoch [6/10], Loss: 89.59697105771019\n",
      "Epoch [7/10], Loss: 89.74316442580451\n",
      "Epoch [8/10], Loss: 89.45288546123201\n",
      "Epoch [9/10], Loss: 89.50607324024988\n",
      "Epoch [10/10], Loss: 89.60752347915891\n"
     ]
    }
   ],
   "source": [
    "#question 2\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  \n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),          \n",
    "])\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "print(\"Training with L1 regularization (Optimizer)\")\n",
    "l1_lambda = 0.01  \n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(inputs)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "\n",
    "        l1_reg = 0\n",
    "        for param in model.parameters():\n",
    "            l1_reg += torch.sum(torch.abs(param))  \n",
    "        \n",
    "        loss += l1_lambda * l1_reg  \n",
    "        \n",
    "        loss.backward() \n",
    "        optimizer.step()  \n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Dropout Regularization (Dropout rate = 0.5):\n",
      "Epoch [1/10], Train Loss: 0.8049, Validation Loss: 0.6932\n",
      "Epoch [2/10], Train Loss: 0.6938, Validation Loss: 0.6934\n",
      "Epoch [3/10], Train Loss: 0.6931, Validation Loss: 0.6926\n",
      "Epoch [4/10], Train Loss: 0.6921, Validation Loss: 0.6917\n",
      "Epoch [5/10], Train Loss: 0.6933, Validation Loss: 0.6922\n",
      "Epoch [6/10], Train Loss: 0.6919, Validation Loss: 0.6918\n",
      "Epoch [7/10], Train Loss: 0.6895, Validation Loss: 0.6747\n",
      "Epoch [8/10], Train Loss: 0.6862, Validation Loss: 0.6876\n"
     ]
    }
   ],
   "source": [
    "#question 3\n",
    "\n",
    "class SimpleCNNWithDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(SimpleCNNWithDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  \n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate) if dropout_rate > 0 else nn.Identity()  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32) \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),          \n",
    "])\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def train_model(dropout_rate=0.0, epochs=10):\n",
    "    model = SimpleCNNWithDropout(dropout_rate=dropout_rate).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs, labels) \n",
    "\n",
    "            loss.backward() \n",
    "            optimizer.step()  \n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)  \n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Training with Dropout Regularization (Dropout rate = 0.5):\")\n",
    "train_model(dropout_rate=0.5)\n",
    "\n",
    "print(\"\\nTraining without Dropout Regularization:\")\n",
    "train_model(dropout_rate=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4\n",
    "\n",
    "class CustomDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(CustomDropout, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:  \n",
    "            # Bernoulli distribution: 1 - dropout_rate gives us the probability of \"keeping\" a neuron\n",
    "            mask = torch.bernoulli(torch.full(x.shape, 1 - self.dropout_rate, device=x.device))\n",
    "            x = x * mask \n",
    "            x = x / (1 - self.dropout_rate)  \n",
    "        return x\n",
    "\n",
    "class SimpleCNNWithCustomDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(SimpleCNNWithCustomDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  \n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.custom_dropout = CustomDropout(dropout_rate) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.custom_dropout(x)  \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class SimpleCNNWithLibraryDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(SimpleCNNWithLibraryDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  \n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),         \n",
    "])\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "def train_model(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(inputs)  \n",
    "            loss = criterion(outputs, labels)  \n",
    "\n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print(\"Training with Custom Dropout Regularization:\")\n",
    "model_with_custom_dropout = SimpleCNNWithCustomDropout(dropout_rate=0.5).to(device)\n",
    "train_model(model_with_custom_dropout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#questions 5\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*64*64, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*64*64)  \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),          \n",
    "])\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = np.inf\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def train_with_early_stopping(model, criterion, optimizer, epochs=20):\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.01)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(inputs)  \n",
    "            loss = criterion(outputs, labels) \n",
    "\n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)  \n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "model_with_early_stopping = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_with_early_stopping.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training with Early Stopping:\")\n",
    "train_with_early_stopping(model_with_early_stopping, criterion, optimizer, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python VENV",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
