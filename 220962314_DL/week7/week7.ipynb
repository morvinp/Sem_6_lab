{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215e58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/Desktop/220962029/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7729914983113607\n",
      "Epoch [2/10], Loss: 0.6932833393414816\n",
      "Epoch [3/10], Loss: 0.6932883546465919\n",
      "Epoch [4/10], Loss: 0.6934845996281457\n",
      "Epoch [5/10], Loss: 0.6933452297770788\n",
      "Epoch [6/10], Loss: 0.6932040008287581\n",
      "Epoch [7/10], Loss: 0.693226000619313\n",
      "Epoch [8/10], Loss: 0.6932457836847457\n",
      "Epoch [9/10], Loss: 0.693385416553134\n",
      "Epoch [10/10], Loss: 0.69475938024975\n",
      "With L2 norm:\n",
      "Epoch [1/10], Loss: 0.7516886497300769\n",
      "Epoch [2/10], Loss: 0.7509025079863412\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = 'cats_and_dogs_filtered'\n",
    "\n",
    "# Download and extract dataset if not already present\n",
    "if not os.path.exists(data_dir):\n",
    "    print(\"Downloading Cats and Dogs dataset...\")\n",
    "    dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
    "    dataset_path = \"cats_and_dogs_filtered.zip\"\n",
    "\n",
    "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
    "\n",
    "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    print(f\"Dataset extracted to {data_dir}\")\n",
    "\n",
    "# Define custom Gaussian noise transformation\n",
    "class Gaussian(object):\n",
    "    def __init__(self, mean: float, var: float):\n",
    "        self.mean = mean\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img: torch.Tensor) -> torch.Tensor:\n",
    "        return img + torch.normal(self.mean, self.var, img.size())\n",
    "\n",
    "# Define the model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  # Adjusted for 256x256 image size\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  # Correct flatten size\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Custom Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, transform=None, str=\"train\"):\n",
    "        self.imgs_path = \".\\\\cats_and_dogs_filtered\\\\\" + str + \"\\\\\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"\\\\\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"\\\\*.jpg\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        self.class_map = {\"dogs\": 0, \"cats\": 1}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.data[idx]\n",
    "        img = PIL.Image.open(img_path)\n",
    "        class_id = self.class_map[class_name]\n",
    "        class_id = torch.tensor(class_id)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, class_id\n",
    "\n",
    "# Define data transformations including Gaussian noise\n",
    "preprocess = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(45),\n",
    "    Gaussian(0, 0.15),\n",
    "])\n",
    "\n",
    "# Load custom dataset\n",
    "train_dataset = MyDataset(transform=preprocess, str=\"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)  # L2 regularization via weight_decay\n",
    "\n",
    "# Training with optimizer's weight_decay\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Training with manual L2 regularization\n",
    "print(\"With L2 norm:\")\n",
    "l2_lambda = 0.01  # Regularization strength\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Calculate L2 regularization manually\n",
    "        l2_reg = 0\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param, 2)  # L2 norm of parameters\n",
    "\n",
    "        loss += l2_lambda * l2_reg  # Add L2 penalty to loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Display augmented images\n",
    "i = 0\n",
    "for data in iter(train_loader):\n",
    "    img, _ = data\n",
    "    tI = T.ToPILImage()\n",
    "    img = tI(img.squeeze())\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    i += 1\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)  # Adjusted for 256x256 image size\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  # Correct flatten size\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "data_dir = 'cats_and_dogs_filtered'  # Adjust this to your dataset path\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training with L1 Regularization\n",
    "l1_lambda = 0.01\n",
    "epochs = 10\n",
    "print(\"Training with L1 regularization:\")\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # L1 regularization\n",
    "        l1_reg = 0\n",
    "        for param in model.parameters():\n",
    "            l1_reg += torch.sum(torch.abs(param))  # L1 norm\n",
    "\n",
    "        loss += l1_lambda * l1_reg  # Add L1 penalty to the loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeee0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# Ensure device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class SimpleCNNWithDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(SimpleCNNWithDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Apply dropout if the dropout rate is > 0\n",
    "        self.dropout = nn.Dropout(dropout_rate) if dropout_rate > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply dropout here\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Data transformation and loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_dir = 'cats_and_dogs_filtered'  # Adjust your data path\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(dropout_rate=0.0, epochs=10):\n",
    "    model = SimpleCNNWithDropout(dropout_rate=dropout_rate).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation loss calculation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)  # Average over validation batches\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], \"\n",
    "              f\"Train Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Training with Dropout Regularization\n",
    "print(\"Training with Dropout Regularization (Dropout rate = 0.5):\")\n",
    "train_model(dropout_rate=0.5, epochs=10)\n",
    "\n",
    "# Training without Dropout Regularization\n",
    "print(\"\\nTraining without Dropout Regularization:\")\n",
    "train_model(dropout_rate=0.0, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22142c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "\n",
    "\n",
    "# Define the Custom Dropout Layer\n",
    "class CustomDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(CustomDropout, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:  # Dropout only during training\n",
    "            # Bernoulli distribution: 1 - dropout_rate gives us the probability of \"keeping\" a neuron\n",
    "            mask = torch.bernoulli(torch.full(x.shape, 1 - self.dropout_rate, device=x.device))\n",
    "            x = x * mask  # Apply mask\n",
    "            x = x / (1 - self.dropout_rate)  # Scale the output\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the CNN Model with Custom Dropout\n",
    "class SimpleCNNWithCustomDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(SimpleCNNWithCustomDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.custom_dropout = CustomDropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.custom_dropout(x)  # Apply custom dropout\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the CNN Model with Library Dropout\n",
    "class SimpleCNNWithLibraryDropout(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(SimpleCNNWithLibraryDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Library Dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply library dropout\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define data transformations and load dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_dir = 'cats_and_dogs_filtered'  # Specify your dataset path\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)  # Average validation loss\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train with Custom Dropout\n",
    "print(\"Training with Custom Dropout Regularization:\")\n",
    "model_with_custom_dropout = SimpleCNNWithCustomDropout(dropout_rate=0.5).to(device)\n",
    "train_model(model_with_custom_dropout)\n",
    "\n",
    "# Train with Library Dropout\n",
    "print(\"\\nTraining with Library Dropout Regularization:\")\n",
    "model_with_library_dropout = SimpleCNNWithLibraryDropout(dropout_rate=0.5).to(device)\n",
    "train_model(model_with_library_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f73c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 32 * 32)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the training and validation datasets and dataloaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "data_dir = 'cats_and_dogs_filtered'  # Specify your dataset path\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 5\n",
    "best_validation_loss = float('inf')\n",
    "current_patience = 0\n",
    "\n",
    "# Initialize your model, loss function, and optimizer\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Function to train the model with early stopping\n",
    "def train_with_early_stopping(num_epochs=50):\n",
    "    global best_validation_loss, current_patience\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validate the model at the end of each epoch\n",
    "        model.eval()\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "        validation_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "              f\"Validation Loss: {validation_loss:.4f}\")\n",
    "\n",
    "        # Early stopping condition\n",
    "        if validation_loss < best_validation_loss:\n",
    "            best_validation_loss = validation_loss\n",
    "            current_patience = 0\n",
    "            # Save the model when validation loss improves\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            current_patience += 1\n",
    "            if current_patience >= patience:\n",
    "                print(f\"Early stopping triggered! No improvement for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model with early stopping\n",
    "train_with_early_stopping(num_epochs=50)\n",
    "\n",
    "# After training, you can load the best model\n",
    "best_model = SimpleCNN().to(device)\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949d7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bb043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python VENV",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
